# åŸºäºYOLOv5çš„å£ç½©æ£€æµ‹

## é¡¹ç›®æ¦‚å†µ

é¡¹ç›®ç›®å½•ç»“æ„ï¼š

![image-20220603222735233](pictures\ç›®å½•ç»“æ„.png)

å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œé¡¹ç›®æ ¹ç›®å½•ä¸º`E:/Projects/FaceMaskDetection`ã€‚é¡¹ç›®åˆ†ä¸ºä¸¤ä¸ªå­å·¥ç¨‹ï¼Œç¬¬ä¸€ä¸ªå·¥ç¨‹ä¸ºdatasetï¼Œç¬¬äºŒä¸ªå­å·¥ç¨‹ä¸ºyolov5ã€‚å­å·¥ç¨‹datasetè´Ÿè´£å¤„ç†æ•°æ®é›†ï¼Œå­å·¥ç¨‹yolov5è´Ÿè´£è®­ç»ƒæ¨¡å‹å¹¶è¾“å‡ºæ£€æµ‹ç»“æœã€‚

é¡¹ç›®æˆ‘å·²å¼€æºè‡³æˆ‘çš„Githubä¸ªäººä¸»é¡µï¼šhttps://github.com/li192863/face-mask-detectionã€‚

## æ•°æ®å¤„ç†

### å‡†å¤‡æ•°æ®é›†

è®ºæ–‡ä¸­åªæåˆ°äº†ç”¨çš„æ˜¯å…¬å¼€å¯ç”¨çš„æ•°æ®é›†ï¼Œä½†å¹¶æœªç»™å‡ºæ•°æ®é›†çš„å‡†ç¡®åœ°å€ã€‚æ­¤å¤„æˆ‘ä½¿ç”¨äº†Kaggleä¸­çš„å£ç½©æ£€æµ‹æ•°æ®é›†ï¼Œè¯¦ç»†åœ°å€ä¸ºhttps://www.kaggle.com/datasets/andrewmvd/face-mask-detectionã€‚è¯¥æ•°æ®é›†æ¯ä¸ªè¾¹ç•Œæ¡†ä¿¡æ¯æœ‰ä¸‰ç±»ï¼Œåˆ†åˆ«ä¸º'with_mask'ï¼ˆ0ï¼‰, 'without_mask'ï¼ˆ1ï¼‰, 'mask_weared_incorrect'ï¼ˆ2ï¼‰ã€‚

<img src="pictures\ä¸‹è½½æ•°æ®é›†.png" alt="image-20220603222458789" style="zoom:50%;" />

åœ¨ç½‘é¡µä¸­ä¸‹è½½æ•°æ®é›†è‡³æœ¬åœ°ï¼Œè§£å‹è‡³`dataset`æ–‡ä»¶å¤¹ä¸‹ï¼ˆæ­¤æ—¶`dataset`æ–‡ä»¶å¤¹ä¸‹åªæœ‰`images`æ–‡ä»¶å¤¹å’Œ`annotations`æ–‡ä»¶å¤¹ï¼‰ã€‚`images`æ–‡ä»¶å¤¹ä¸‹å­˜æ”¾853å¼ å›¾ç‰‡ï¼ˆ`maksssksksss*.png`ï¼‰ï¼Œ`annotations`æ–‡ä»¶å¤¹ä¸‹å­˜æ”¾853å¼ å›¾ç‰‡çš„æ ‡æ³¨ä¿¡æ¯ï¼ˆ`maksssksksss*.xml`ï¼‰ã€‚æ¯å¼ å›¾ç‰‡ä¸æ ‡æ³¨æ–‡ä»¶é™¤åç¼€åå¤–åç§°ç›¸åŒã€‚

![image-20220603230956589](pictures\datasetå­é¡¹ç›®.png)

### åˆ’åˆ†æ•°æ®é›†

åœ¨`dataset`æ–‡ä»¶å¤¹ä¸‹åˆ›å»º`split_train_val.py`ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
import os
import random
import argparse


def parse_args():
    """
    ä¼ å…¥å‘½ä»¤è¡Œå‚æ•°
    :return: å‚æ•°
    """
    parser = argparse.ArgumentParser()
    # xmlæ–‡ä»¶(åŸå§‹æ³¨è§£)çš„åœ°å€(annotations)
    parser.add_argument('--xml_path', default='annotations', type=str, help='input xml label path')
    # txtæ–‡ä»¶(åˆ’åˆ†åæ–‡ä»¶å)çš„åœ°å€(image_sets)
    parser.add_argument('--txt_path', default='image_sets', type=str, help='output path of splited file names')
    # txtæ–‡ä»¶(åˆ’åˆ†åè·¯å¾„å)çš„åœ°å€(dataset_path)
    parser.add_argument('--dataset_path', default='dataset_path', type=str, help='output path of splited file paths')
    opt = parser.parse_args()
    return opt


def generate_index(xml_path, trainval_percent=0.9, train_percent=0.8):
    """
    ç”Ÿæˆè®­ç»ƒé›†/éªŒè¯é›†/æµ‹è¯•é›†ç´¢å¼•
    :param xml_path: åŸå§‹æ³¨è§£è·¯å¾„åœ°å€
    :param trainval_percent: è®­ç»ƒé›†ä¸éªŒè¯é›†å æ•°æ®é›†åˆ’åˆ†æ¯”
    :param train_percent: è®­ç»ƒé›†å è®­ç»ƒé›†éªŒè¯é›†åˆ’åˆ†æ¯”
    :return: xmlæ–‡ä»¶åˆ—è¡¨ è®­ç»ƒé›†ä¸éªŒè¯é›†ç´¢å¼•åˆ—è¡¨ è®­ç»ƒé›†ç´¢å¼•åˆ—è¡¨
    """
    total_xml = os.listdir(xml_path)
    num = len(total_xml)
    list_index = range(num)
    tv = int(num * trainval_percent)
    tr = int(tv * train_percent)

    trainval_idx = random.sample(list_index, tv)
    train_idx = random.sample(trainval_idx, tr)
    return total_xml, trainval_idx, train_idx


def generate_txt(txt_path, total_xml, trainval_idx, train_idx, prefix='', suffix=''):
    """
    ç”Ÿæˆtxtæ–‡ä»¶
    :param txt_path: åˆ’åˆ†åå­˜æ”¾txtæ–‡ä»¶çš„è·¯å¾„åœ°å€
    :param total_xml: xmlæ–‡ä»¶åˆ—è¡¨
    :param trainval_idx: è®­ç»ƒé›†ä¸éªŒè¯é›†ç´¢å¼•åˆ—è¡¨
    :param train_idx: è®­ç»ƒé›†ç´¢å¼•åˆ—è¡¨
    :param prefix: txtæ–‡ä»¶ä¸­å›¾ç‰‡åç§°å‰ç¼€
    :param suffix: txtæ–‡ä»¶ä¸­å›¾ç‰‡åç§°åç¼€
    """
    if not os.path.exists(txt_path):
        os.makedirs(txt_path)
    
    # file_trainval = open(txt_path + '/trainval.txt', 'w')
    file_test = open(txt_path + '/test.txt', 'w')
    file_train = open(txt_path + '/train.txt', 'w')
    file_val = open(txt_path + '/val.txt', 'w')

    for i in range(len(total_xml)):
        line = prefix + total_xml[i][:-4] + suffix + '\n'
        if i in trainval_idx:
            # file_trainval.write(line)
            if i in train_idx:
                file_train.write(line)
            else:
                file_val.write(line)
        else:
            file_test.write(line)

    # file_trainval.close()
    file_train.close()
    file_val.close()
    file_test.close()
    

if __name__ == '__main__':
    # ä¼ å…¥å‘½ä»¤è¡Œå‚æ•°
    opt = parse_args()
    xml_path, txt_path, dataset_path = opt.xml_path, opt.txt_path, opt.dataset_path
    # å†™å…¥txtæ–‡ä»¶
    total_xml, trainval_idx, train_idx = generate_index(xml_path)
    generate_txt(txt_path, total_xml, trainval_idx, train_idx)
    generate_txt(dataset_path, total_xml, trainval_idx, train_idx, prefix='E:/Projects/FaceMaskDetection/dataset/images/', suffix='.png')

```

ç¨‹åºè¿è¡Œç»“æŸåï¼Œå­å·¥ç¨‹å‡ºç°äº†`image_sets`æ–‡ä»¶å¤¹ä¸`dataset_path`æ–‡ä»¶å¤¹ã€‚

`image_sets`æ–‡ä»¶å¤¹ä¸‹å­˜æ”¾`test.txt`ã€`train.txt`ã€`val.txt`ï¼Œåˆ†åˆ«å¯¹åº”æµ‹è¯•é›†ã€è®­ç»ƒé›†ã€éªŒè¯é›†ï¼Œæ¯ä¸ª`.txt`æ–‡ä»¶æ¯ä¸€è¡Œéƒ½ä¸ºä¸€ä¸ªæ–‡ä»¶åã€‚

![image-20220603224821152](pictures\image_setsæ–‡ä»¶ç¤ºä¾‹.png)

`dataset_path`æ–‡ä»¶å¤¹ä¸‹å­˜æ”¾`test.txt`ã€`train.txt`ã€`val.txt`ï¼Œåˆ†åˆ«å¯¹åº”æµ‹è¯•é›†ã€è®­ç»ƒé›†ã€éªŒè¯é›†ï¼Œæ¯ä¸ª`.txt`æ–‡ä»¶æ¯ä¸€è¡Œéƒ½ä¸ºä¸€ä¸ªå›¾ç‰‡çš„ç»å¯¹è·¯å¾„ã€‚

![image-20220603224954691](pictures\dataset_pathæ–‡ä»¶ç¤ºä¾‹.png)

### æ ‡è®°æ•°æ®é›†

åœ¨`dataset`æ–‡ä»¶å¤¹ä¸‹åˆ›å»º`xml_to_yolo.py`ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
import torch.utils.data as data
from PIL import Image, ImageDraw
import os
import os.path
import sys

if sys.version_info[0] == 2:
    import xml.etree.cElementTree as ET
else:
    import xml.etree.ElementTree as ET

DS_CLASSES = ('with_mask', 'without_mask', 'mask_weared_incorrect')  # æ•°æ®é›†ç±»å‹
DS_ROOT = '.'  # æ•°æ®é›†æ ¹ç›®å½•


class TransformAnnotation(object):
    """
    è½¬æ¢æ³¨è§£ç±»
    """
    def __init__(self, class_to_idx=None, keep_difficult=False):
        """
        æ„é€ è½¬æ¢æ³¨è§£å¯¹è±¡
        :param class_to_idx: å­—å…¸ {ç±»å0:0, ç±»å1: 1, ...}
        :param keep_difficult: æ˜¯å¦ä¿ç•™å›°éš¾å€¼
        """
        self.class_to_idx = class_to_idx or dict(zip(DS_CLASSES, range(len(DS_CLASSES))))
        self.keep_difficult = keep_difficult

    def __call__(self, target, is_yolo_format=False):
        """
        è½¬æ¢æ³¨è§£ç”Ÿæˆåˆ—è¡¨
        :param target: xmlæ–‡ä»¶æ ¹èŠ‚ç‚¹
        :param is_yolo_format: æ˜¯å¦ä¸ºyoloæ ¼å¼
        :return: åˆ—è¡¨[cls_idx, x_center, y_center, width, height] or [xmin, ymin, xmax, ymax, cla_name]
        """
        res = []
        for obj in target.iter('object'):
            difficult = int(obj.find('difficult').text) == 1
            if not self.keep_difficult and difficult:
                continue
            name = obj[0].text.lower().strip()
            bbox = obj[5]
            bndbox = [int(bb.text) - 1 for bb in bbox]  # [xmin, ymin, xmax, ymax]

            if is_yolo_format:
                width = int(target.find('size').find('width').text)
                height = int(target.find('size').find('height').text)

                xmin, ymin, xmax, ymax = bndbox
                class_idx = self.class_to_idx[name]
                x_center = ((xmin + xmax) / 2.0 - 1) / width
                y_center = ((ymin + ymax) / 2.0 - 1) / height
                box_width = (xmax - xmin) / width
                box_height = (ymax - ymin) / height

                res += [[class_idx, x_center, y_center, box_width, box_height]]
            else:
                res += [bndbox + [name]]
        return res

    def get_yolo_txt(self, target):
        """
        ç”Ÿæˆyoloæ ¼å¼çš„txtæ–‡æœ¬
        :param target:
        :return:
        """
        boxes = self.__call__(target, is_yolo_format=True)
        res = ''
        for i in range(len(boxes)):
            class_idx, x_center, y_center, box_width, box_height = boxes[i]
            line = str(class_idx) + ' ' + str(x_center) + ' ' + str(y_center) + ' ' + str(box_width) + ' ' + str(box_height)
            res += line + '\n'
        return res

    def transform_xml_to_txt(self, xml_path, txt_path):
        """
        è½¬æ¢xmlä¸ºtxtæ–‡æœ¬
        :param xml_path: å­˜æ”¾xmlæ–‡ä»¶å¤¹è·¯å¾„
        :param txt_path: å­˜æ”¾txtæ–‡ä»¶å¤¹è·¯å¾„
        :return:
        """
        if not os.path.exists(txt_path):  # è‹¥ç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º
            os.makedirs(txt_path)
        for dirname, _, filenames in os.walk(xml_path):
            for filename in filenames:
                target = ET.parse(os.path.join(dirname, filename)).getroot()
                txt_string = self.get_yolo_txt(target)
                with open(os.path.join(txt_path, filename[:-4] + '.txt'), 'w+') as f:
                    f.write(txt_string)


class Detection(data.Dataset):
    """
    æ£€æµ‹ç±»
    """
    def __init__(self, root, image_set, transform=None, target_transform=None):
        """
        æ„é€ æ£€æµ‹å¯¹è±¡
        :param root: æ ¹ç›®å½•
        :param image_set: å›¾ç‰‡é›†ç±»å‹ åŒ…æ‹¬train test val
        :param transform: å›¾ç‰‡è½¬æ¢
        :param target_transform: ç›®æ ‡è½¬æ¢
        """
        self.root = root
        self.image_set = image_set
        self.transform = transform
        self.target_transform = target_transform

        self._annopath = os.path.join(self.root, 'annotations', '%s.xml')
        self._imgpath = os.path.join(self.root, 'images', '%s.png')
        self._imgsetpath = os.path.join(self.root, 'image_sets', '%s.txt')

        with open(self._imgsetpath % self.image_set) as f:
            self.ids = f.readlines()
        self.ids = [x.strip('\n') for x in self.ids]

    def __getitem__(self, index):
        """
        è·å–ç¬¬indexå¼ å›¾ç‰‡
        :param index:
        :return:
        """
        img_id = self.ids[index]
        target = ET.parse(self._annopath % img_id).getroot()
        img = Image.open(self._imgpath % img_id).convert('RGB')
        if self.transform is not None:
            img = self.transform(img)
        if self.target_transform is not None:
            target = self.target_transform(target)
        return img, target

    def __len__(self):
        """
        è·å–æ£€æµ‹å›¾ç‰‡ä¸ªæ•°
        :return:
        """
        return len(self.ids)

    def show(self, index):
        """
        æ˜¾ç¤ºç¬¬indexå¼ å›¾ç‰‡
        :param index:
        :return:
        """
        img, target = self.__getitem__(index)
        draw = ImageDraw.Draw(img)
        for obj in target:
            draw.rectangle(obj[0:4], outline=(255, 0, 0))
            draw.text(obj[0:2], obj[4], fill=(0, 255, 0))
        img.show()


if __name__ == '__main__':
    # ç”Ÿæˆæ‰€æœ‰æ–‡ä»¶çš„æ ‡ç­¾
    transform = TransformAnnotation()
    transform.transform_xml_to_txt(xml_path='./annotations', txt_path='./labels')
    # å–å‡ºè®­ç»ƒé›†çš„ä¸€å¼ å›¾ç‰‡æŸ¥çœ‹æ•ˆæœ
    dataset = Detection(DS_ROOT, image_set='train', target_transform=transform)
    print(len(dataset))
    img, target = dataset[3]
    print(target)
    dataset.show(3)

```

ç¨‹åºè¿è¡Œç»“æŸåï¼Œå­å·¥ç¨‹ä¸­å‡ºç°äº†`labels`æ–‡ä»¶å¤¹ã€‚æ§åˆ¶å°è¾“å‡ºè®­ç»ƒæ•°æ®é›†çš„é•¿åº¦ï¼Œè¾“å‡ºè®­ç»ƒæ•°æ®é›†ä¸­çš„ç¬¬ä¸‰å¼ å›¾ç‰‡çš„æ ‡ç­¾ï¼Œå¹¶æ˜¾ç¤ºç¬¬ä¸‰å¼ å›¾ç‰‡ä¸å…¶æ ‡æ³¨ã€‚

![image-20220603225920882](pictures\æ ‡è®°æ•°æ®é›†è¾“å‡ºç»“æœ1.png)

![image-20220603225844033](pictures\æ ‡è®°æ•°æ®é›†è¾“å‡ºç»“æœ2.png)

`labels`æ–‡ä»¶å¤¹ä¸‹å­˜æ”¾853å¼ å›¾ç‰‡çš„æ ‡æ³¨ä¿¡æ¯ï¼ˆ`maksssksksss*.txt`ï¼‰ã€‚ä¸€ä¸ª`.txt`æ–‡ä»¶å¯¹åº”ä¸€å¼ `.png`å›¾ç‰‡ï¼Œæ–‡ä»¶æ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªç‰©ä½“ï¼Œæ–‡ä»¶æ¯ä¸€è¡Œä»£è¡¨çš„å«ä¹‰ä¸ºè¾¹ç•Œæ¡†ç±»åˆ«ï¼ˆ0/1/2ï¼‰ã€ä¸­å¿ƒç‚¹xåæ ‡ï¼ˆç›¸å¯¹äºæ•´ä¸ªå›¾ç‰‡å®½ï¼‰ã€ä¸­å¿ƒç‚¹yåæ ‡ï¼ˆç›¸å¯¹äºæ•´ä¸ªå›¾ç‰‡é«˜ï¼‰ã€è¾¹ç•Œæ¡†å®½ï¼ˆç›¸å¯¹äºæ•´ä¸ªå›¾ç‰‡å®½ï¼‰ã€è¾¹ç•Œæ¡†é«˜ï¼ˆç›¸å¯¹äºæ•´ä¸ªå›¾ç‰‡é«˜ï¼‰ã€‚è¯¥æ ¼å¼ç”±yolov5å®˜æ–¹æŒ‡å®šã€‚

![image-20220603230158030](pictures\labelsæ–‡ä»¶ç¤ºä¾‹.png)

è‡³æ­¤ï¼Œ`dataset`å­å·¥ç¨‹å®Œæˆï¼Œè¯¥å·¥ç¨‹æˆåŠŸåˆ’åˆ†äº†æ•°æ®é›†ï¼Œå¹¶å°†æ ‡æ³¨ä¿¡æ¯è½¬åŒ–ä¸ºyoloæ ¼å¼ã€‚

## æ¨¡å‹è®­ç»ƒ

### å‡†å¤‡ä»£ç 

åœ¨`FaceMaskDetection`æ–‡ä»¶å¤¹ä¸‹æ‰“å¼€ç»ˆç«¯powershellï¼Œè¾“å…¥å¦‚ä¸‹æŒ‡ä»¤ï¼š

```shell
git clone https://github.com/ultralytics/yolov5  # å…‹éš†é¡¹ç›®æºä»£ç 
cd yolov5  # æ‰“å¼€å­å·¥ç¨‹æ–‡ä»¶å¤¹
conda create -n yolov5  # åˆ›å»ºç¯å¢ƒåä¸ºyolov5 ä¸“é—¨ç”¨äºå¤„ç†è¯¥é¡¹ç›®
conda activate yolov5  # åˆ‡æ¢ç¯å¢ƒä¸ºyolov5
pip install -r requirements.txt -i https://mirrors.tuna.tsinghua.edu.cn/help/pypi/  # ä½¿ç”¨æ¸…åé•œåƒå®‰è£…ä¾èµ–
```

`yolov5`æ–‡ä»¶å¤¹ç›®å½•å¦‚ä¸‹ï¼š

![image-20220603232341599](pictures\yolov5å­é¡¹ç›®.png)

### å‡†å¤‡æ•°æ®

åœ¨`yolov5`æ–‡ä»¶å¤¹ä¸‹åˆ›å»º`data/FMD.yaml`ï¼Œé…ç½®ä¿¡æ¯å¦‚ä¸‹ï¼š

```yaml
# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ../dataset # dataset root dir
train: dataset_path/train.txt  # train images (relative to 'path') 613 images
val: dataset_path/val.txt  # val images (relative to 'path') 154 images
test: dataset_path/test.txt # test images (optional) 86 images

# Classes
nc: 3  # number of classes
names: ['with_mask', 'without_mask', 'mask_weared_incorrect']  # class names

```

è¿™é‡Œ`train.txt`ã€`val.txt`ã€`test.txt`ä¸­åˆ†åˆ«æŒ‡æ˜äº†è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†çš„æ‰€æœ‰å›¾ç‰‡çš„ç»å¯¹è·¯å¾„ã€‚YOLOv5å®˜æ–¹è§„å®šæ–‡ä»¶æŸ¥æ‰¾`images`æ–‡ä»¶å¤¹ä¸‹æ¯ä¸€å¼ å›¾ç‰‡æ—¶ï¼Œå…¶è‡ªåŠ¨æŸ¥æ‰¾ä¸`images`æ–‡ä»¶å¤¹å¹³çº§çš„`labels`æ–‡ä»¶å¤¹ç›¸åŒæ–‡ä»¶åçš„`.txt`æ–‡ä»¶ä½œä¸ºå›¾ç‰‡çš„å¯¹åº”æ ‡ç­¾ã€‚å®˜æ–¹è§£é‡Šå¦‚ä¸‹ï¼š

![image-20220603233849752](pictures\å®˜æ–¹æ–‡æ¡£è¯´æ˜.png)

### ä¿®æ”¹æ¨¡å‹

åœ¨`yolov5`æ–‡ä»¶å¤¹ä¸‹ä¿®æ”¹`models/yolov5s.yaml`ï¼Œé…ç½®ä¿¡æ¯å¦‚ä¸‹ï¼š

```yaml
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 3  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]

# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]

```

YOLOv5å®˜æ–¹æä¾›5ç§æ¨¡å‹ï¼ˆYOLOv5nã€YOLOv5sã€YOLOv5mã€YOLOv5lã€YOLOv5xï¼‰ä»¥é€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯ï¼Œè¿™é‡Œæˆ‘é€‰æ‹©ä½¿ç”¨YOLOv5sã€‚

### é…ç½®è®­ç»ƒ

åœ¨`yolov5`æ–‡ä»¶å¤¹ä¸‹ä¿®æ”¹`train.py`ä¸‹çš„`parse_opt`å‡½æ•°ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
def parse_opt(known=False):
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', type=str, default=ROOT / 'weights/yolov5s.pt', help='initial weights path')
    parser.add_argument('--cfg', type=str, default='models/yolov5s.yaml', help='model.yaml path')
    parser.add_argument('--data', type=str, default=ROOT / 'data/FMD.yaml', help='dataset.yaml path')
    parser.add_argument('--hyp', type=str, default=ROOT / 'data/hyps/hyp.scratch-low.yaml', help='hyperparameters path')
    parser.add_argument('--epochs', type=int, default=200)
    parser.add_argument('--batch-size', type=int, default=4, help='total batch size for all GPUs, -1 for autobatch')
    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='train, val image size (pixels)')
    parser.add_argument('--rect', action='store_true', help='rectangular training')
    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')
    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')
    parser.add_argument('--noval', action='store_true', help='only validate final epoch')
    parser.add_argument('--noautoanchor', action='store_true', help='disable AutoAnchor')
    parser.add_argument('--noplots', action='store_true', help='save no plot files')
    parser.add_argument('--evolve', type=int, nargs='?', const=300, help='evolve hyperparameters for x generations')
    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')
    parser.add_argument('--cache', type=str, nargs='?', const='ram', help='--cache images in "ram" (default) or "disk"')
    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')
    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')
    parser.add_argument('--optimizer', type=str, choices=['SGD', 'Adam', 'AdamW'], default='SGD', help='optimizer')
    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')
    parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')
    parser.add_argument('--project', default=ROOT / 'runs/train', help='save to project/name')
    parser.add_argument('--name', default='exp', help='save to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--quad', action='store_true', help='quad dataloader')
    parser.add_argument('--cos-lr', action='store_true', help='cosine LR scheduler')
    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')
    parser.add_argument('--patience', type=int, default=100, help='EarlyStopping patience (epochs without improvement)')
    parser.add_argument('--freeze', nargs='+', type=int, default=[0], help='Freeze layers: backbone=10, first3=0 1 2')
    parser.add_argument('--save-period', type=int, default=-1, help='Save checkpoint every x epochs (disabled if < 1)')
    parser.add_argument('--local_rank', type=int, default=-1, help='DDP parameter, do not modify')

    # Weights & Biases arguments
    parser.add_argument('--entity', default=None, help='W&B: Entity')
    parser.add_argument('--upload_dataset', nargs='?', const=True, default=False, help='W&B: Upload data, "val" option')
    parser.add_argument('--bbox_interval', type=int, default=-1, help='W&B: Set bounding-box image logging interval')
    parser.add_argument('--artifact_alias', type=str, default='latest', help='W&B: Version of dataset artifact to use')

    opt = parser.parse_known_args()[0] if known else parser.parse_args()
    return opt
```

è¿™é‡Œæˆ‘é€‰æ‹©é¢„è®­ç»ƒæƒé‡å­˜æ”¾äº`weights`æ–‡ä»¶å¤¹ä¸‹ï¼Œæ•°æ®é…ç½®ä¸º`data/FMD.yaml`ï¼Œè½®æ•°ä¸º200ï¼Œæ¯ä¸ªæ‰¹æ¬¡å¤§å°ä¸º4å¼ å›¾ç‰‡ã€‚

### å¼€å§‹è®­ç»ƒ

è¿è¡Œ`train.py`ï¼Œæ‰§è¡Œè®­ç»ƒã€‚è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹è®­ç»ƒä¿¡æ¯ä¼šä¿å­˜åœ¨`runs/train/exp`æ–‡ä»¶å¤¹ä¸‹ã€‚

PRæ›²çº¿ï¼š

![PR_curve](pictures\PR_curve.png)

æŸå¤±å˜åŒ–ï¼š

![image-20220604000849011](pictures\result.png)

## é¢„æµ‹å›¾ç‰‡

### é…ç½®æ£€æµ‹

åœ¨`yolov5`æ–‡ä»¶å¤¹ä¸‹ä¿®æ”¹`detect.py`ä¸‹çš„`parse_opt`å‡½æ•°ï¼Œä»£ç å¦‚ä¸‹ï¼š

```python
def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument('--weights', nargs='+', type=str, default=ROOT / 'runs/train/exp/weights/best.pt', help='model path(s)')
    parser.add_argument('--source', type=str, default=ROOT / 'data/images', help='file/dir/URL/glob, 0 for webcam')
    parser.add_argument('--data', type=str, default=ROOT / 'data/FMD.yaml', help='(optional) dataset.yaml path')
    parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')
    parser.add_argument('--conf-thres', type=float, default=0.25, help='confidence threshold')
    parser.add_argument('--iou-thres', type=float, default=0.45, help='NMS IoU threshold')
    parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--view-img', action='store_true', help='show results')
    parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')
    parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')
    parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')
    parser.add_argument('--nosave', action='store_true', help='do not save images/videos')
    parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --classes 0, or --classes 0 2 3')
    parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')
    parser.add_argument('--augment', action='store_true', help='augmented inference')
    parser.add_argument('--visualize', action='store_true', help='visualize features')
    parser.add_argument('--update', action='store_true', help='update all models')
    parser.add_argument('--project', default=ROOT / 'runs/detect', help='save results to project/name')
    parser.add_argument('--name', default='exp', help='save results to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--line-thickness', default=3, type=int, help='bounding box thickness (pixels)')
    parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')
    parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')
    parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')
    parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')
    opt = parser.parse_args()
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand
    print_args(vars(opt))
    return opt
```

è¿™é‡Œæˆ‘é€‰æ‹©æƒé‡ä¸º`runs/train/exp/weights/best.pt`ï¼Œæ•°æ®é…ç½®ä¸º`data/FMD.yaml`ã€‚

### é¢„æµ‹å›¾ç‰‡

è¿è¡Œä¸Šè¿°ä»£ç ï¼Œæ‰§è¡Œæ£€æµ‹ã€‚æ£€æµ‹å®Œæˆåï¼Œæ¨¡å‹æ£€æµ‹ä¿¡æ¯ä¼šä¿å­˜åœ¨`runs/detect/exp`æ–‡ä»¶å¤¹ä¸‹ã€‚

`detect.py`å¯ä»¥é€‰æ‹©æ‘„åƒå¤´ã€å›¾ç‰‡ã€è§†é¢‘ç­‰ä½œä¸ºè¾“å…¥è¿›è¡Œæ£€æµ‹.

```shell
python detect.py --source 0  # webcam
                          img.jpg  # image
                          vid.mp4  # video
                          path/  # directory
                          path/*.jpg  # glob
                          'https://youtu.be/Zgi9g1ksQHc'  # YouTube
                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream
```

è‡³æ­¤ï¼Œ`yolov5`å­å·¥ç¨‹å®Œæˆï¼Œè¯¥å·¥ç¨‹æˆåŠŸè®­ç»ƒäº†æ¨¡å‹ï¼Œå¹¶ä¸”æˆåŠŸæ£€æµ‹äº†å›¾ç‰‡ã€‚

### æ£€æµ‹ç»“æœ

ä»¥ä¸‹ä¸ºä¸€äº›æ£€æµ‹ç»“æœå±•ç¤ºã€‚

![image-20220604002908692](pictures\pic1.png)

![image-20220604003514098](pictures\pic2.png)

![image-20220604003131098](pictures\pic3.png)

